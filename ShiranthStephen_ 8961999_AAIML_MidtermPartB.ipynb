{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2576a080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Using cached numpy-2.3.0-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.7.0-cp313-cp313-win_amd64.whl.metadata (14 kB)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Using cached scipy-1.15.3-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached numpy-2.3.0-cp313-cp313-win_amd64.whl (12.7 MB)\n",
      "Using cached scikit_learn-1.7.0-cp313-cp313-win_amd64.whl (10.7 MB)\n",
      "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Using cached scipy-1.15.3-cp313-cp313-win_amd64.whl (41.0 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, numpy, joblib, scipy, scikit-learn\n",
      "Successfully installed joblib-1.5.1 numpy-2.3.0 scikit-learn-1.7.0 scipy-1.15.3 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679fd182",
   "metadata": {},
   "source": [
    "**1.Wine Dataset Classification with GaussianNB and MultinomialNB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c53e26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB Accuracy: 1.0\n",
      "MultinomialNB Accuracy: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "wine = load_wine()\n",
    "X, y = wine.data, wine.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Gaussian Naive Bayes\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "gnb_pred = gnb.predict(X_test)\n",
    "\n",
    "# Train Multinomial Naive Bayes\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "mnb_pred = mnb.predict(X_test)\n",
    "\n",
    "# Evaluate the Models\n",
    "gnb_acc = accuracy_score(y_test, gnb_pred)\n",
    "mnb_acc = accuracy_score(y_test, mnb_pred)\n",
    "\n",
    "print(\"GaussianNB Accuracy:\", gnb_acc)\n",
    "print(\"MultinomialNB Accuracy:\", mnb_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f850355b",
   "metadata": {},
   "source": [
    "**Observations and Reflections**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce46ac2",
   "metadata": {},
   "source": [
    "GaussianNB performed significantly superior to MultinomialNB on the wine dataset.\n",
    "This is expected because GaussianNB assumes features are normally distributed, which suits the continuous nature of the wine dataset.\n",
    "MultinomialNB is better suited for discrete/numbered data, i.e., word frequencies in text classification, so it does less here.\n",
    "For this dataset, the preferred model is GaussianNB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27505d4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e4dfdf2",
   "metadata": {},
   "source": [
    "**2.Iris Dataset with Logistic Regression and Cross Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e233b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.96666667 1.         0.93333333 0.96666667 1.        ]\n",
      "Mean Accuracy: 0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "log_regression = LogisticRegression(max_iter=200)\n",
    "scores = cross_val_score(log_regression, X, y, cv=5)\n",
    "\n",
    "print(\"Cross-Validation Scores:\", scores)\n",
    "print(\"Mean Accuracy:\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06390d1c",
   "metadata": {},
   "source": [
    "**Observations And Reflections**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028b8f31",
   "metadata": {},
   "source": [
    "The logistic regression model achieved very high accuracy in all the folds: (in most cases above 95%).\n",
    "The mean accuracy gives a solid measure of model performance, minimizing bias from any individual train/test split.\n",
    "Logistic regression is good on small, clean datasets like Iris where features are linearly separable.\n",
    "Cross-validation gives a shade of credibility to model evaluation by conferring stability and preventing overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
